---
title: "Technical"
---

TODO: Explain scraping process in detail. Database setup, and APIs

### Scraping pipeline

- **Define data source(s)**: List all platforms we scrape homework from (e.g. Google Sheets/Forms, LMS exports, CSV uploads).
- **Clarify trigger**: Decide if scraping runs on a schedule (cron/Lambda) or webhook-based.
- **Implement scraper job**:
  - Fetch raw homework data from the chosen source(s).
  - Normalize fields into a common shape (student identifier, assignment, due date, submission status, links, timestamps).
- **Deduplication rules**: Define how to handle duplicate rows / re-runs (idempotency key, last-updated wins, etc.).
- **Error handling**: Log failures with enough context (student, assignment, source row) and mark records as `errored` instead of dropping them.

### Database design

- **Choose collection/table name** (e.g. `homework_status`).
- **Define schema** (fields and types):
  - Student reference (e.g. `studentId` / `externalStudentId`).
  - Assignment identifier and title.
  - Status enum (`"Not Started"`, `"In Progress"`, `"Submitted"`, `"Missing"`, etc.).
  - Source metadata (which scraper, raw source id/row).
  - Timestamps: `assignedAt`, `dueAt`, `submittedAt`, `lastSyncedAt`.
- **Indexes**:
  - By `studentId` + `dueAt` for fast dashboard queries.
  - By assignment and status for reporting.
- **Migration strategy**: Decide how to backfill historical data and how many days/weeks of homework to keep.

### APIs

- **GET homework for a student**
  - Endpoint: e.g. `GET /homework/{studentId}`.
  - Filters: by date range, status, course/class.
  - Pagination and sorting (default sort by `dueAt` ascending).
- **Bulk sync endpoint (internal)**:
  - Endpoint: e.g. `POST /internal/homework/sync`.
  - Auth restricted to internal services.
  - Accepts batch payload from scraper and upserts into `homework_status`.
- **Update overrides**
  - Endpoint: e.g. `POST /homework/override`.
  - Allow coaches/admins to manually fix status or dates when the scraper data is wrong.

### Coach portal integration

- **Homework view API contract**: Confirm exactly what the coach portal needs (fields, labels, grouping).
- **Performance checks**: Ensure queries remain fast when a student has many assignments.
- **Empty states & errors**: Decide what the UI shows if:
  - No homework found.
  - Scraper is failing / last sync is too old.

### Security, auth, and observability

- **Auth**: Limit homework APIs to authenticated coach/admin roles; do not leak homework across students.
- **PII handling**: Avoid storing unnecessary PII in logs; redact where needed.
- **Monitoring**:
  - Add metrics for scraper runs (success/failure counts, duration).
  - Alert when scraper fails N times in a row or `lastSyncedAt` is too old.
- **Audit logs**: Track manual overrides (who changed what and when).

### Local and staging setup

- Seed sample homework data for local development and QA.
- Document `.env` / config required for scraping and DB connections.
- Add scripts or commands to run a full “scrape → store → API → portal” flow in staging..